{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['SPARK_HOME']=r'C:/spark/'\n",
    "os.environ['HADOOP_HOME'] = r'C:/hadoop/'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']='jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']='lab'\n",
    "os.environ['PYSPARK_PYTHON']='python'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# Crear Sesion spark\n",
    "spark = SparkSession.builder.appName(\"App1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\Windows\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------+\n",
      "|titulo_id|              titulo|          tipo|\n",
      "+---------+--------------------+--------------+\n",
      "|        1|       Consultas SQL|          bbdd|\n",
      "|        3|Grupo recursos Azure|administracion|\n",
      "|        4|  .NET Framework 4.5|  programacion|\n",
      "|        5|     Programacion C#|           dev|\n",
      "|        7|            Power BI|            BI|\n",
      "|        8|Administracion Sq...|administracion|\n",
      "+---------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear la tabla \"bde.titulos\"\n",
    "titulos_data = [\n",
    "    ('1', 'Consultas SQL', 'bbdd'),\n",
    "    ('3', 'Grupo recursos Azure', 'administracion'),\n",
    "    ('4', '.NET Framework 4.5', 'programacion'),\n",
    "    ('5', 'Programacion C#', 'dev'),\n",
    "    ('7', 'Power BI', 'BI'),\n",
    "    ('8', 'Administracion Sql server', 'administracion')\n",
    "]\n",
    "\n",
    "titulos_df = spark.createDataFrame(titulos_data, [\"titulo_id\", \"titulo\", \"tipo\"])\n",
    "\n",
    "# Mostrar\n",
    "titulos_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------+-------------+\n",
      "|TituloId|NombreAutor|ApellidosAutor|TelefonoAutor|\n",
      "+--------+-----------+--------------+-------------+\n",
      "|       3|      David|         Saenz|     99897867|\n",
      "|       8|        Ana|          Ruiz|     99897466|\n",
      "|       2|     Julian|         Perez|     99897174|\n",
      "|       1|     Andres|      Calamaro|     99876869|\n",
      "|       4|      Cidys|      Castillo|    998987453|\n",
      "|       5|      Pedro|        Molina|     99891768|\n",
      "+--------+-----------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear \"bde.autores\" \n",
    "autores_data = [\n",
    "    ('3', 'David', 'Saenz', '99897867'),\n",
    "    ('8', 'Ana', 'Ruiz', '99897466'),\n",
    "    ('2', 'Julian', 'Perez', '99897174'),\n",
    "    ('1', 'Andres', 'Calamaro', '99876869'),\n",
    "    ('4', 'Cidys', 'Castillo', '998987453'),\n",
    "    ('5', 'Pedro', 'Molina', '99891768')\n",
    "]\n",
    "\n",
    "autores_df = spark.createDataFrame(autores_data, [\"TituloId\", \"NombreAutor\", \"ApellidosAutor\", \"TelefonoAutor\"])\n",
    "\n",
    "# Mostrar\n",
    "autores_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mi forma de hacer el procedimiento\n",
    "def transform_dim_titulos(titulos_df, autores_df):\n",
    "    transformed_df = titulos_df.join(autores_df, titulos_df.titulo_id == autores_df.TituloId, \"inner\") \\\n",
    "        .withColumnRenamed(\"NombreAutor\", \"NombreCompleto\") \\\n",
    "        .select(\"titulo_id\", \"titulo\", \"tipo\", \"NombreCompleto\", \"TelefonoAutor\")\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------+--------------+-------------+\n",
      "|titulo_id|              titulo|          tipo|NombreCompleto|TelefonoAutor|\n",
      "+---------+--------------------+--------------+--------------+-------------+\n",
      "|        1|       Consultas SQL|          bbdd|        Andres|     99876869|\n",
      "|        3|Grupo recursos Azure|administracion|         David|     99897867|\n",
      "|        4|  .NET Framework 4.5|  programacion|         Cidys|    998987453|\n",
      "|        5|     Programacion C#|           dev|         Pedro|     99891768|\n",
      "|        8|Administracion Sq...|administracion|           Ana|     99897466|\n",
      "+---------+--------------------+--------------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_titulos_df = transform_dim_titulos(titulos_df, autores_df)\n",
    "\n",
    "# Mostrar resultado\n",
    "dim_titulos_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
