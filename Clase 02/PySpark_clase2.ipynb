{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['SPARK_HOME']=r'C:/spark/'\n",
    "os.environ['HADOOP_HOME'] = r'C:/hadoop/'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']='jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']='lab'\n",
    "os.environ['PYSPARK_PYTHON']='python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------------------+--------------------+--------------------+------------+---+\n",
      "|customerid|            name|          occupation|               email|             company| phonenumber|Age|\n",
      "+----------+----------------+--------------------+--------------------+--------------------+------------+---+\n",
      "|         0|    David Melton|          Unemployed|    DMelton@zoho.com|Morris, Winters a...|409-093-0748| 16|\n",
      "|         1|Michael Gonzalez|             Student|Gonzalez_Michael@...|  Hernandez and Sons|231-845-0673| 19|\n",
      "|         2|   Amanda Wilson|             Student|Amanda.Wilson75@v...|Mooney, West and ...|844-276-4552| 18|\n",
      "|         3|   Robert Thomas|Engineer, structural| RThomas@xfinity.com|      Johnson-Gordon|410-404-8000| 25|\n",
      "|         4|      Eddie Hall|             Surgeon|EddieHall@outlook...|          Dawson LLC|872-287-2196| 30|\n",
      "+----------+----------------+--------------------+--------------------+--------------------+------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Crear Sesion spark\n",
    "spark = SparkSession.builder.appName(\"App1\").getOrCreate()\n",
    "# Leer la data\n",
    "customers = spark.read.csv(\"customers.csv\", header=True, inferSchema=True)\n",
    "agents = spark.read.csv(\"agents.csv\", header=True, inferSchema=True)\n",
    "calls = spark.read.csv(\"calls.csv\", header=True, inferSchema=True)\n",
    "# Mostremos la data\n",
    "customers.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo consulta OLTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+--------+--------+-----------+\n",
      "|callid|agentid|customerid|pickedup|duration|productsold|\n",
      "+------+-------+----------+--------+--------+-----------+\n",
      "| 10000|      4|         6|       1|     130|          1|\n",
      "| 10001|      5|         7|       1|     131|          0|\n",
      "| 10002|     10|       260|       0|       0|          0|\n",
      "| 10003|      3|         5|       1|      60|          1|\n",
      "| 10004|     10|       731|       1|      90|          0|\n",
      "| 10005|      4|       415|       0|       0|          0|\n",
      "+------+-------+----------+--------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert_data = [\n",
    "    (10000, 4, 6, 1, 130, 1),\n",
    "    (10001, 5, 7, 1, 131, 0),\n",
    "    (10002, 10, 260, 0, 0, 0),\n",
    "    (10003, 3, 5, 1, 60, 1),\n",
    "    (10004, 10, 731, 1, 90, 0),\n",
    "    (10005, 4, 415, 0, 0, 0)\n",
    "]\n",
    "schema=calls.columns\n",
    "# Dataframe a insertar\n",
    "insert_df = spark.createDataFrame(insert_data, schema=schema)\n",
    "insert_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+--------+--------+-----------+\n",
      "|callid|agentid|customerid|pickedup|duration|productsold|\n",
      "+------+-------+----------+--------+--------+-----------+\n",
      "|     0|     10|       179|       0|       0|          0|\n",
      "|     1|      5|       691|       1|     116|          0|\n",
      "|     2|     10|        80|       1|     165|          0|\n",
      "|     3|      6|       629|       1|     128|          0|\n",
      "|     4|      8|       318|       1|     205|          0|\n",
      "|     5|      7|       319|       1|     225|          1|\n",
      "|     6|     10|       265|       1|     211|          0|\n",
      "|     7|      9|       625|       0|       0|          0|\n",
      "|     8|      5|       877|       0|       0|          0|\n",
      "|     9|      5|       191|       1|     145|          0|\n",
      "+------+-------+----------+--------+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calls_final = calls.union(insert_df)\n",
    "calls_final.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(callid=10001, agentid=5, customerid=7, pickedup=1, duration=131, productsold=0),\n",
       " Row(callid=10002, agentid=10, customerid=260, pickedup=0, duration=0, productsold=0),\n",
       " Row(callid=10003, agentid=3, customerid=5, pickedup=1, duration=60, productsold=1),\n",
       " Row(callid=10004, agentid=10, customerid=731, pickedup=1, duration=90, productsold=0),\n",
       " Row(callid=10005, agentid=4, customerid=415, pickedup=0, duration=0, productsold=0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls_final.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio OLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------+\n",
      "|         AgentName|   CustomerName|duration|\n",
      "+------------------+---------------+--------+\n",
      "|       Randy Moore|Alexandra Allen|      49|\n",
      "|      Lisa Cordova| Carlos Bennett|      57|\n",
      "|      Angel Briggs|Brandy Ferguson|      47|\n",
      "|        Dana Hardy|Erin Mccullough|      51|\n",
      "|        Paul Nunez| Matthew Martin|      44|\n",
      "|       Todd Morrow|  Shari Barnett|      37|\n",
      "|      Gloria Singh|     Jenny Dean|      36|\n",
      "|           Agent X|  Daniel Hughes|      22|\n",
      "|Christopher Moreno|    John George|      55|\n",
      "|  Michele Williams|Matthew Schultz|      62|\n",
      "|    Jocelyn Parker|   William Rice|      72|\n",
      "+------------------+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Poner los Spark Dataframe en tablas de SQL temporarias\n",
    "calls.createOrReplaceTempView(\"calls\")\n",
    "agents.createOrReplaceTempView(\"agents\")\n",
    "customers.createOrReplaceTempView(\"customers\")\n",
    "\n",
    "# SQL para usar Spark SQL\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT a.name AS AgentName, cu.name AS CustomerName, x.duration\n",
    "    FROM (\n",
    "        SELECT ca.agentid, ca.duration, max(customerid) AS cid\n",
    "        FROM (\n",
    "            SELECT agentid, min(duration) as fastestcall\n",
    "            FROM calls\n",
    "            WHERE productsold = 1\n",
    "            GROUP BY agentid\n",
    "        ) min\n",
    "        JOIN calls ca ON ca.agentid = min.agentid AND ca.duration = min.fastestcall\n",
    "        WHERE productsold = 1\n",
    "        GROUP BY ca.agentid, ca.duration\n",
    "    ) x\n",
    "    JOIN agents a ON x.agentid = a.agentid\n",
    "    JOIN customers cu ON cu.customerid = x.cid\n",
    "\"\"\")\n",
    "\n",
    "# Mostrar el resultado\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------+\n",
      "|         AgentName|   CustomerName|duration|\n",
      "+------------------+---------------+--------+\n",
      "|    Jocelyn Parker|   William Rice|      72|\n",
      "|  Michele Williams|Matthew Schultz|      62|\n",
      "|      Lisa Cordova| Carlos Bennett|      57|\n",
      "|Christopher Moreno|    John George|      55|\n",
      "|        Dana Hardy|Erin Mccullough|      51|\n",
      "|       Randy Moore|Alexandra Allen|      49|\n",
      "|      Angel Briggs|Brandy Ferguson|      47|\n",
      "|        Paul Nunez| Matthew Martin|      44|\n",
      "|       Todd Morrow|  Shari Barnett|      37|\n",
      "|      Gloria Singh|     Jenny Dean|      36|\n",
      "|           Agent X|  Daniel Hughes|      22|\n",
      "+------------------+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "result.orderBy('duration',ascending=False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
